model = Sequential()
model.add(Conv2D(16, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=input_shape,
                 kernel_initializer='he_uniform'))
model.add(MaxPooling2D(pool_size=(2, 4), strides=(2, 2)))
#model.add(BatchNormalization(axis=-1))
model.add(Dropout(0.25))
model.add(Conv2D(42, kernel_size=(4, 8), padding='same', activation='relu', kernel_initializer='he_uniform'))
model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
#model.add(BatchNormalization(axis=-1))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(600, activation='relu', kernel_initializer='he_uniform'))
#model.add(BatchNormalization())
model.add(Dropout(0.5))
#model.add(Dense(60, activation='relu', kernel_initializer='he_uniform'))
#model.add(Dropout(0.5))
model.add(Dense(nClasses, activation='softmax', kernel_initializer='glorot_uniform', use_bias = True))

#model.load_weights('alya.h5')


model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adam(lr=0.0001),
              metrics=['accuracy'])

class AccuracyHistory(keras.callbacks.Callback):
    def on_train_begin(self, logs={}):
        self.acc = []

    def on_epoch_end(self, batch, logs={}):
        self.acc.append(logs.get('acc'))


history = AccuracyHistory()

model.fit(x_train, y_train,
          batch_size=batch_size,
          epochs=epochs,
          verbose=1,
          validation_data=(x_test, y_test),
          callbacks=[history]
          )

